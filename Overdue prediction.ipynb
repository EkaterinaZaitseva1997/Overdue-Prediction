{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from wrantools.db import WMDBAdapter\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert your credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from wrantools.vault import get_vault_client\n",
    "vault = get_vault_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is taken from the main data source of deployments, change data range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "select depl.* ,\n",
    "       sf2.upgrade_score as \"Upgrade Score\"\n",
    "from tableau_deployments depl\n",
    "left join (select wrike_account_id,\n",
    "                  created_date,\n",
    "                  industry,\n",
    "                  upgrade_score,\n",
    "                  row_number() over\n",
    "                      (partition by wrike_account_id order by created_date desc) as rank\n",
    "            from derived_sf2_account\n",
    "            group by 1,2,3,4) sf2\n",
    "    on depl.\"Account Number\"=sf2.wrike_account_id and sf2.rank=1\n",
    "where \"Bill Date\" BETWEEN '2018-01-01' AND '2019-10-31'\n",
    "\"\"\"\n",
    "db_client = WMDBAdapter(use_pandas=True)\n",
    "df = db_client.pentaho.simple_get(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary = df.describe(include='all')\n",
    "summary = summary.transpose()\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as math\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All fields where there are dates, transform to date type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Bill Date']=pd.to_datetime(df['Bill Date'])\n",
    "df['Became Paid Day']=pd.to_datetime(df['Became Paid Day'])\n",
    "df['Start Date']=pd.to_datetime(df['Start Date'])\n",
    "df['End Date']=pd.to_datetime(df['End Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make new fields for prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Age (Months)']=np.where(df['Became Paid Day']==\"None\",0,(df['Bill Date']-df['Became Paid Day']))\n",
    "df['Age (Months)']=df['Age (Months)'] / pd.Timedelta(30, unit='d')\n",
    "df['Age (Months)']=df['Age (Months)'][df['Age (Months)'].notnull()].apply(lambda x: int(x))\n",
    "df['Age (Months)'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import date\n",
    "def ifnull(var, val):\n",
    "    if pd.isnull(var):\n",
    "        return val\n",
    "    return var\n",
    "df['Today']=pd.to_datetime(date.today())\n",
    "# df['Duration Days']=np.where(pd.isnull(pd.to_datetime(df['End Date'])-pd.to_datetime(df['Start Date'])), \n",
    "#                              pd.to_datetime(df['Today'])-pd.to_datetime(df['Start Date']), \n",
    "#                              pd.to_datetime(df['End Date'])-pd.to_datetime(df['Start Date']))\n",
    "df['Days from Today']=np.where(pd.isnull(pd.to_datetime(df['Today'])-pd.to_datetime(df['Start Date'])), \n",
    "                              pd.to_datetime(df['Today'])-pd.to_datetime(df['Bill Date']), \n",
    "                              pd.to_datetime(df['Today'])-pd.to_datetime(df['Start Date']))\n",
    "df['Duration Days']=pd.to_datetime(df['End Date'])-pd.to_datetime(df['Start Date'])\n",
    "#df['Duration Days']=np.where(pd.isnull(df['Duration Days']),\n",
    "#                             pd.to_datetime(df['Today'])-pd.to_datetime(df['Bill Date']),df['Duration Days'])\n",
    "df['Duration Days']=df['Duration Days'] / pd.Timedelta(1, unit='d')\n",
    "df['Days from Today']=df['Days from Today'] / pd.Timedelta(1, unit='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Package'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make less deployment packages, unification of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Package (group)']=df['Package'].replace(['Large ','Expansion Large '],'Large')\n",
    "df['Package (group)']=df['Package (group)'].replace(['Medium','26-50 User Deployment Package','Expansion Medium'],'Medium')\n",
    "df['Package (group)']=df['Package (group)'].replace(['Expansion Small'],'Small')\n",
    "df['Package (group)'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditions for overdue definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "package_durations=df[df['Project Status'].isin(['Completed', 'Deemed Delivered'])].groupby(by=['Package (group)','Remote / Onsite'],as_index=False)['Duration Days'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "package_durations.rename(columns={'Duration Days':'Package (group) durations'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "package_durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.merge(df,package_durations,how='left', on=['Package (group)','Remote / Onsite'], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Overdue Days']=np.where(pd.isnull(df['Duration Days']),\n",
    "                           df['Days from Today']-df['Package (group) durations'],\n",
    "                           df['Duration Days']-df['Package (group) durations'])\n",
    "df['Duration Overall']=np.where(pd.isnull(df['Duration Days']),\n",
    "                                df['Days from Today'],\n",
    "                                df['Duration Days'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.catplot(x=\"Package (group)\", y=\"Overdue Days\", col=\"Remote / Onsite\", kind=\"box\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df['Project Status'].isin(['Completed', 'Deemed Delivered'])].groupby(by=['Package (group)','Remote / Onsite'],as_index=False)['Overdue Days'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conditions = [((df['Package (group)'] =='JumpStart') & (df['Duration Overall'] > 45))|\n",
    "              ((df['Package (group)'] =='Small') & (df['Duration Overall'] > 60))|\n",
    "              ((df['Package (group)'] =='Medium') & (df['Duration Overall'] > 75))|\n",
    "              ((df['Package (group)'] =='Large') & (df['Duration Overall'] > 90))|\n",
    "              ((df['Package (group)'] =='Custom Development') & (df['Duration Overall'] > 90))|\n",
    "              ((df['Package (group)'] =='Custom Deployment') & (df['Duration Overall'] > 90))|\n",
    "              ((df['Package (group)'] =='PS Pilot') & (df['Duration Overall'] > 90))|\n",
    "              ((df['Package (group)'] =='Integrate') & (df['Duration Overall'] > 90))]\n",
    "choices = ['T']\n",
    "df['Overdue'] = np.select(conditions, choices, default='F')\n",
    "df[['Package','Package (group)','Duration Overall','Duration Months','Overdue']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Duration Days'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Duration Days'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Duration Overall'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df['Duration Months']>6]['Bookings Amount'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Project Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Duration Months'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Full Start Date'] = np.where(df['Start Date'].notnull(),\n",
    "                      df['Start Date'],\n",
    "                      df['Bill Date'])\n",
    "df['Full Start Date'].isnull().sum()\n",
    "df['Workload Month']=df['Full Start Date'].apply(lambda x:pd.date_range(start=x, periods=1, freq='M').date[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def range_date(start,periods):\n",
    "    return pd.date_range(start=start, periods=periods+1, freq='M')\n",
    "df['Array Busy Months']=df.apply(lambda x: range_date(x['Full Start Date'], x['Duration Months']), axis=1)\n",
    "df['Array Busy Months']=df['Array Busy Months'].apply(lambda x: x.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Array Busy Months']=df['Array Busy Months'].apply(lambda x: x.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "depl_list=[]\n",
    "month_list=[]\n",
    "for i in df.index:\n",
    "    month_array = df.get_value(i,'Array Busy Months')\n",
    "    depl = df.get_value(i,'Deployment Consultant')\n",
    "    for month in month_array:\n",
    "        depl_list.append(depl)\n",
    "        month_list.append(month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "workload=pd.DataFrame({'Deployment Consultant':depl_list,'Workload Month':month_list})\n",
    "workload.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "workload=workload.groupby(by=['Deployment Consultant','Workload Month'],as_index=False).size().reset_index(name='Workload Deployments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.merge(df,workload,how='left', on=['Deployment Consultant','Workload Month'], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop(['Full Start Date', 'Workload Month', 'Array Busy Months'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['DR']=np.where((df['Project Status'].isin(['In Progress','New','Started','On Hold']))|(df['End Date']>df['Today']),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.boxplot(x=\"Package (group)\", y=\"Duration Days\", data=df,linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dur_quantile95 = df.groupby(['Package (group)'])['Duration Days'].quantile(.95).reset_index(name='Duration Days (95 quantile)')\n",
    "df=pd.merge(df,dur_quantile95,how='left', on=['Package (group)'], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns=['Bill Number','Deployment ID','Bookings Amount','Deployment Owner','Project Status',\n",
    "         'Outsource / Internal','Deployment Consultant','NA / INTL','Technical Invoice','Duration Months','Age (Months)',\n",
    "        'Package Detailed','Remote / Onsite','Metal Bucket','Region','SaaS Product','Seats','MRR',\n",
    "         'Account Status','Tier','Overdue','CSM Segment','DR','Workload Deployments',\n",
    "         'Package (group) durations','Duration Days (95 quantile)','Overdue Days', 'Duration Overall']\n",
    "dfo=df[columns]\n",
    "dfo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NA can be misinterpreted, so change it to North America"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfo['NA / INTL']=dfo['NA / INTL'].replace('NA','North America')\n",
    "dfo['NA / INTL'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Project Status'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter technical invoices and error deployments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfo=dfo[dfo['Technical Invoice']!=True]\n",
    "dfo=dfo[dfo['Project Status'].isin(['Error','Canceled','Cancelled']) == False]\n",
    "dfo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfo=dfo.drop(columns=['Technical Invoice','Metal Bucket'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfo.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfo[dfo['Bill Number']=='INV00366333'].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For train drop deployments that are completed, but for test check on the completed deployments\n",
    "Sekect only objects columns and drop Bill Number and Deployment ID for model training\n",
    "Encode all objects values, because classifier doesn't recognize dtype objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfo[dfo['Project Status'].isin(['Completed', 'Deemed Delivered'])].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfo[dfo['Project Status'].isin(['Completed', 'Deemed Delivered']) == False].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "traindf=dfo[(dfo['Project Status'].isin(['Completed', 'Deemed Delivered']))&(df['Duration Months']<=6)].dropna()\n",
    "#traindf=traindf[traindf['Duration Overall']<traindf['Duration Days (95 quantile)']]\n",
    "testdf=dfo[dfo['Project Status'].isin(['Completed', 'Deemed Delivered']) == False].dropna()\n",
    "enc = LabelEncoder()\n",
    "obj_test = testdf.select_dtypes(include=['object']).copy()\n",
    "obj_test = obj_test.drop(columns=['Bill Number','Deployment ID','NA / INTL','Region',\n",
    "                                  'Outsource / Internal','Remote / Onsite','CSM Segment','Package Detailed',\n",
    "                                  'Deployment Owner','Project Status'])\n",
    "\n",
    "obj_test = obj_test.apply(lambda col: enc.fit_transform(col))\n",
    "df_test=pd.concat([testdf[['Bill Number','Deployment ID','Bookings Amount','Overdue Days',\n",
    "                           'Seats','MRR','Workload Deployments','Package (group) durations']].dropna(),obj_test],axis=1)\n",
    "obj_train = traindf.select_dtypes(include=['object']).copy()\n",
    "obj_train = obj_train.drop(columns=['Bill Number','Deployment ID','NA / INTL','Region',\n",
    "                                  'Outsource / Internal','Remote / Onsite','CSM Segment','Package Detailed',\n",
    "                                   'Deployment Owner','Project Status'])\n",
    "obj_train = obj_train.apply(lambda col: enc.fit_transform(col))\n",
    "df_train=pd.concat([traindf[['Bill Number','Deployment ID','Bookings Amount','Duration Months','Overdue Days',\n",
    "                             'Seats','MRR','Workload Deployments','Package (group) durations']].dropna(),obj_train],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(traindf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "feature_cols=['Bill Number','Deployment ID','Bookings Amount',\n",
    "              'Deployment Consultant','Package (group) durations',\n",
    "              'Overdue','Workload Deployments','Overdue Days',\n",
    "             'SaaS Product','Seats','MRR','Account Status','Tier']\n",
    "data_inputs = df_train[feature_cols]\n",
    "expected_output = df_train[['Duration Months']].replace(0,0.01).astype(str)\n",
    "inputs_train, inputs_test, expected_output_train, expected_output_test = train_test_split(data_inputs, expected_output, test_size=0.1, random_state=42)\n",
    "inputs_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\", color_codes=True);\n",
    "palette = sns.xkcd_palette(['dark blue', 'gold', 'orange'])\n",
    "sns.pairplot(df_train[['Duration Months','Bookings Amount', \n",
    "                      'Seats', 'MRR', 'Workload Deployments','Overdue Days',\n",
    "                      'Package (group) durations','Overdue']], hue = 'Overdue', diag_kind = 'kde', palette= palette, plot_kws=dict(alpha = 0.7),\n",
    "                   diag_kws=dict(shade=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\", color_codes=True);\n",
    "palette = sns.xkcd_palette(['dark blue', 'gold', 'orange'])\n",
    "sns.pairplot(df_train[['Duration Months','Overdue','Overdue Days']], diag_kind = 'kde', palette= palette, plot_kws=dict(alpha = 0.7),\n",
    "                   diag_kws=dict(shade=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regressor = LinearRegression()  \n",
    "X=inputs_train[['Duration Overall','Overdue']]\n",
    "regressor.fit(X, expected_output_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(regressor.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coeff_df = pd.DataFrame(regressor.coef_.T, X.columns, columns=['Coefficient'])  \n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test=inputs_test[['Duration Overall','Overdue']]\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics.mean_absolute_error(np.array(expected_output_test.iloc[:,0]),y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "rmse = (np.sqrt(mean_squared_error(np.array(expected_output_train), regressor.predict(X))))\n",
    "r2 = r2_score(np.array(expected_output_train), regressor.predict(X))\n",
    "\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))\n",
    "print(\"\\n\")\n",
    "\n",
    "# model evaluation for testing set\n",
    "rmse = (np.sqrt(mean_squared_error(np.array(expected_output_test.iloc[:,0]), y_pred)))\n",
    "r2 = r2_score(np.array(expected_output_test.iloc[:,0]), y_pred)\n",
    "\n",
    "print(\"The model performance for testing set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Overdue'].replace({'T':1,'F':0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict_reg=regressor.predict(df[['Duration Overall','Overdue']]).astype('int')\n",
    "predict_reg=pd.DataFrame(predict_reg,columns=['Overdue Days Predict'])\n",
    "final=pd.concat([df.reset_index(drop=True),predict_reg], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "def add_days(date, days):\n",
    "    return date + timedelta(days=days)\n",
    "final['Predict End Date']=final.apply(lambda x: add_days(x['Start Date'], x['Package (group) durations']), axis=1)\n",
    "final['Predict End Date']=final.apply(lambda x: add_days(x['Predict End Date'], x['Overdue Days Predict']), axis=1)\n",
    "#final['Overdue Days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final['Predict Month']=final['Predict End Date'].apply(lambda x:x.replace(day=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_not_close=final[final['Project Status'].isin(['Completed', 'Deemed Delivered']) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_not_close['Bookings Amount'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted_revenue=final_not_close.pivot(columns='Predict Month', values='Bookings Amount').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(predicted_revenue, columns = ['DR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(df_test.head().columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(df_train.head().columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt','log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [5, 10, 15]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [4, 6, 8, 10]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(inputs_train.drop(columns=['Bill Number','Deployment ID']), expected_output_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    accuracy = metrics.accuracy_score(test_labels, predictions)\n",
    "    print('Model Performance')\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    return accuracy\n",
    "\n",
    "base_model = RandomForestClassifier(n_estimators = 10, random_state = 42)\n",
    "base_model.fit(inputs_train.drop(columns=['Bill Number','Deployment ID']), \n",
    "               expected_output_train)\n",
    "base_accuracy = evaluate(base_model, inputs_test.drop(columns=['Bill Number','Deployment ID']), expected_output_test.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate(best_random, inputs_test.drop(columns=['Bill Number','Deployment ID']), expected_output_test.replace(0,0.01).iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [5,10,20,30],\n",
    "    'max_features': ['auto'],\n",
    "    'min_samples_leaf': [2, 3, 4],\n",
    "    'min_samples_split': [3, 5, 7],\n",
    "    'n_estimators': [50, 100, 200]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 x 4 x 1 x 3 x 3 x 4 = 144 combonations for 3-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_search.fit(inputs_train.drop(columns=['Bill Number','Deployment ID']), expected_output_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_grid = grid_search.best_estimator_\n",
    "grid_accuracy = evaluate(best_grid, inputs_test.drop(columns=['Bill Number','Deployment ID']), expected_output_test.replace(0,0.01).iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=500,min_samples_split=10,max_features='sqrt',\n",
    "                            min_samples_leaf=5, max_depth=30, bootstrap=True, random_state=42)\n",
    "rf.fit(inputs_train.drop(columns=['Bill Number','Deployment ID']), expected_output_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc = metrics.accuracy_score(expected_output_test.iloc[:,0], rf.predict(inputs_test.drop(columns=['Bill Number','Deployment ID'])))\n",
    "print(\"Accuracy = {:.2f}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict=pd.DataFrame(rf.predict_proba(df_test.drop(columns=['Bill Number','Deployment ID'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_pred=pd.concat([df_test.reset_index(drop=True),predict], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_pred.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,7):\n",
    "    final_pred[str(i)+'_pred']=final_pred.loc[:,i]*final_pred['Bookings Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_pred['Bookings Amount'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_pred[final_pred['Overdue Days']>180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_pred=final_pred.merge(df[['Bill Number','Deployment ID','Bookings Amount','Start Date','Bill Date']],how='left', on=['Bill Number','Deployment ID','Bookings Amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "def add_month(date, month):\n",
    "    date = date.replace(day=1)\n",
    "    date = date + month*timedelta(days=32)\n",
    "    date = date.replace(day=1)\n",
    "    return date\n",
    "final_pred['Full Start Date'] = np.where(final_pred['Start Date'].notnull(),\n",
    "                      final_pred['Start Date'],\n",
    "                      final_pred['Bill Date'])\n",
    "final_pred['Next Month']=final_pred.apply(lambda x: add_month(x['Full Start Date'], 1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_pred.groupby(['Next Month'])['1_pred'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bins = np.linspace(300, 600, 50)\n",
    "\n",
    "plt.hist(inputs_train['Duration Overall'], bins, alpha=0.5, label='train')\n",
    "plt.hist(df_test['Duration Overall'], bins, alpha=0.5, label='real')\n",
    "plt.legend(prop={'size': 10})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 600, 50)\n",
    "\n",
    "plt.hist(inputs_train['Duration Overall'], bins, alpha=0.5, label='train')\n",
    "plt.hist(df_test['Duration Overall'], bins, alpha=0.5, label='real')\n",
    "plt.legend(prop={'size': 10})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict_array=rf.predict(df_test.drop(columns=['Bill Number','Deployment ID'])).astype('int')\n",
    "predict=pd.DataFrame(predict_array,columns=['Overdue Days'])\n",
    "final=pd.concat([df_test.reset_index(drop=True),predict], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf.predict(df_test.drop(columns=['Bill Number','Deployment ID'])).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final.to_csv(r'G:\\My Drive\\PS Model Automation\\File Name.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'feature': data_inputs.drop(columns=['Bill Number','Deployment ID']).columns,\n",
    "              'importance': rf.feature_importances_}).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import xgboost\n",
    "# from sklearn import model_selection\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# model = xgboost.XGBClassifier()\n",
    "# model.fit(inputs_train.drop(columns=['Bill Number','Deployment ID']), expected_output_train)\n",
    "# print(model)\n",
    "# y_pred = model.predict(X_test)\n",
    "# predictions = [round(value) for value in y_pred]\n",
    "# # evaluate predictions\n",
    "# accuracy = accuracy_score(y_test, predictions)\n",
    "# print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # make predictions for test data\n",
    "# y_pred = model.predict(inputs_test.drop(columns=['Bill Number','Deployment ID']))\n",
    "# predictions = [round(value) for value in y_pred]\n",
    "# # evaluate predictions\n",
    "# accuracy = accuracy_score(expected_output_test, predictions)\n",
    "# print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame({'feature': data_inputs.drop(columns=['Bill Number','Deployment ID']).columns,\n",
    "#               'importance': model.feature_importances_}).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "traindf=dfo[dfo['Project Status'].isin(['Completed', 'Deemed Delivered'])].dropna()\n",
    "traindf=traindf[traindf['Duration Days']<traindf['Duration Days (95 quantile)']]\n",
    "testdf=dfo[dfo['Project Status'].isin(['Completed', 'Deemed Delivered']) == False].drop('Duration Days',axis=1).dropna()\n",
    "\n",
    "feature_cols=['Bill Number','Deployment ID','Bookings Amount','Deployment Owner','Project Status',\n",
    "              'Deployment Consultant','Package (group) durations',\n",
    "              'Package Detailed','Overdue','Workload Deployments','Account Industry',\n",
    "             'SaaS Product','Seats','MRR','Account Status','Tier','Days from Today']\n",
    "data_inputs = traindf[feature_cols]\n",
    "expected_output = traindf[['Duration Days']]\n",
    "inputs_train, inputs_test, expected_output_train, expected_output_test = train_test_split(data_inputs, expected_output, test_size=0.1, random_state=42)\n",
    "inputs_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from catboost import CatBoostClassifier, FeaturesData, Pool\n",
    "\n",
    "le=preprocessing.LabelEncoder()\n",
    "expected_output = le.fit_transform(expected_output_train)\n",
    "feature_num=['Bookings Amount','Seats','MRR','Days from Today',\n",
    "             'Workload Deployments','Package (group) durations']\n",
    "feature_cat=['Deployment Owner', 'Project Status',\n",
    "       'Deployment Consultant',\n",
    "       'Package Detailed', 'SaaS Product',\n",
    "       'Account Status', 'Tier', 'Overdue', 'Account Industry']\n",
    "inputs_train[feature_num]=inputs_train[feature_num].astype('float32')\n",
    "inputs_test[feature_num]=inputs_test[feature_num].astype('float32')\n",
    "inputs_train[feature_cat]=inputs_train[feature_cat].astype('str')\n",
    "inputs_test[feature_cat]=inputs_test[feature_cat].astype('str')\n",
    "data=FeaturesData(\n",
    "        num_feature_data=inputs_train[feature_num].values,\n",
    "        cat_feature_data=inputs_train[feature_cat].values,\n",
    "        num_feature_names=feature_num,\n",
    "        cat_feature_names=feature_cat)\n",
    "\n",
    "train_data = Pool(\n",
    "    data=FeaturesData(\n",
    "        num_feature_data=inputs_train[feature_num].values,\n",
    "        cat_feature_data=inputs_train[feature_cat].values,\n",
    "        num_feature_names=feature_num,\n",
    "        cat_feature_names=feature_cat),\n",
    "    label=expected_output_train\n",
    ")\n",
    "test_data = Pool(\n",
    "    data=FeaturesData(\n",
    "        num_feature_data=inputs_test[feature_num].values,\n",
    "        cat_feature_data=inputs_test[feature_cat].values,\n",
    "        num_feature_names=feature_num,\n",
    "        cat_feature_names=feature_cat),\n",
    "    label=expected_output_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(iterations=800, learning_rate=1, depth=10)\n",
    "# Fit model\n",
    "model.fit(train_data,plot=True,eval_set=test_data)\n",
    "# Get predicted classes\n",
    "preds_class = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (\"test_score: {0:.2f}, train_score: {1:.2f}\".format(model.score(test_data),model.score(train_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(round(model.eval_metrics(test_data, metrics=['R2'])['R2'][-1],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'feature': model.feature_names_,\n",
    "              'importance': np.round(model.get_feature_importance(train_data),1)}).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cat_model.score(inputs_test.drop(columns=['Bill Number','Deployment ID']), expected_output_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame({'feature': data_inputs.drop(columns=['Bill Number','Deployment ID']).columns,\n",
    "#               'importance': cat_model.get_feature_importance()}).sort_values('importance', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
